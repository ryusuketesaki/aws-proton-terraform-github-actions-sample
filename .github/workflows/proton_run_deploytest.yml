# This is a workflow created to run based on a commit made by AWS Proton
# It only works if there is only one resource modified as part of the commit.

name: 'proton-run-deploytest'

on:
  workflow_dispatch:

jobs:
  get-deployment-data:
    name: Get Deployment Data
    runs-on: ubuntu-latest

    outputs:
      role_arn: arn:aws:iam::808225968452:role/ExampleGithubRole
      environment: tesaki-testenv-fargate
      resource_arn: ${{ steps.get-data.outputs.resource_arn }}
      working_directory: ${{ steps.get-data.outputs.working_directory }}
      deployment_id: ${{ steps.get-data.outputs.deployment_id }}
      target_region: ap-northeast-1
      proton_region: ${{ steps.get-data.outputs.proton_region }}
      state_bucket: ${{ steps.get-data.outputs.state_bucket }}
      is_deleted: ${{ steps.get-data.outputs.is_deleted }}
    
    permissions:
      id-token: write
      contents: read

    continue-on-error: true
    
    steps:
    # Checkout the repository to the GitHub Actions runner
    - name: Checkout
      uses: actions/checkout@v2
  
# This action only supports pull requests and pushes, workflow_dispatch events are not supported. Please submit an issue on this action's GitHub repo if you believe this in correct.  
#     - name: Get changed files
#       id: files
#       uses: jitterbit/get-changed-files@v1
      
#     - name: Find modified resource
#       id: find-modified
#       run: |
#         found=false
#         for changed_file in ${{ steps.files.outputs.all }}; do
#           if [[ "$changed_file" == *".proton/deployment-metadata.json" ]]; then
#             echo "found file"
#             if [[ "$found" == true ]]; then
#               echo "More than one resource found to have a new deployment, I'm not sure which one to update, exiting."
#               exit 1
#             fi
#             echo "setting found to true"
#             found=true
#             echo "setting outputs"
#             echo "::set-output name=deployment-metadata-path::$changed_file"
#           fi
#         done
#         if [[ "$found" == false ]]; then
#           echo "No change made to deployment-metadata.json, exiting"
#           exit 1
#         fi
    
#     - name: Get data
#       id: get-data
#       run: |
#         modified_resource_arn=$(jq -r '(.resourceMetadata.arn // .componentMetadata.arn)' ${{ steps.find-modified.outputs.deployment-metadata-path }})
#         echo "::set-output name=resource_arn::$modified_resource_arn"
        
#         IFS=':'
#         read -a split_arn <<< "$modified_resource_arn"
#         proton_region=${split_arn[3]}
#         echo "::set-output name=proton_region::$proton_region"

#         deployment_id=$(jq -r '.deploymentId' ${{ steps.find-modified.outputs.deployment-metadata-path }})
#         echo "::set-output name=deployment_id::$deployment_id"

#         is_deleted=$(jq -r '.isResourceDeleted' ${{ steps.find-modified.outputs.deployment-metadata-path }})
#         echo "::set-output name=is_deleted::$is_deleted"


#         if [[ "$modified_resource_arn" == *":environment/"* ]]; then
#           environment_name=${modified_resource_arn##*/}
#           working_directory="$environment_name/"
#         elif [[ "$modified_resource_arn" == *"/service-instance/"* ]]; then
#           environment_arn=$(jq -r '.resourceMetadata.environmentArn' ${{ steps.find-modified.outputs.deployment-metadata-path }})
#           environment_name=${environment_arn##*/}

#           resource_portion=${modified_resource_arn##*:}
#           IFS='/'
#           read -a split_resources <<< "$resource_portion"

#           service_name=${split_resources[1]}
#           instance_name=${split_resources[3]}

#           working_directory=$environment_name/$service_name-$instance_name/
#         elif [[ "$modified_resource_arn" == *"/pipeline"* ]]; then
#           environment_name="pipeline"

#           resource_portion=${modified_resource_arn##*:}
#           IFS='/'
#           read -a split_resources <<< "$resource_portion"

#           service_name=${split_resources[1]}

#           working_directory=$service_name/pipeline
#         elif [[ "$modified_resource_arn" == *":component/"* ]]; then
#           environment_arn=$(jq -r '.componentMetadata.environmentArn' ${{ steps.find-modified.outputs.deployment-metadata-path }})
#           environment_name=${environment_arn##*/}
#           resource_portion=${modified_resource_arn##*:}
#           IFS='/'
#           read -a split_resources <<< "$resource_portion"
#           component_name=${split_resources[1]}
#           working_directory=$environment_name/$component_name/  
#         fi

#         if [[ $(jq -r --arg env $environment_name 'has($env)' env_config.json) = "true" ]]; then
#           role_arn=$(jq -r --arg env $environment_name '.[$env]["role"]' env_config.json)
#           target_region=$(jq -r --arg env $environment_name '.[$env]["region"]' env_config.json)
#           state_bucket=$(jq -r --arg env $environment_name '.[$env]["state_bucket"]' env_config.json)   
#         else     
#           if [[ $(jq -r --arg env $environment_name 'has("*")' env_config.json) = "true" ]]; then
#             role_arn=$(jq -r --arg env $environment_name '.["*"]["role"]' env_config.json)
#             target_region=$(jq -r --arg env $environment_name '.["*"]["region"]' env_config.json)
#             state_bucket=$(jq -r --arg env $environment_name '.["*"]["state_bucket"]' env_config.json)
#           else
#             echo "Missing $environment_name or * from env_config.json, exiting"
#             exit 1
#           fi
#         fi
        
#         echo "::set-output name=working_directory::$working_directory"
#         echo "::set-output name=environment::$environment_name"
        
#         echo "::set-output name=role_arn::$role_arn"
#         echo "::set-output name=target_region::$target_region"
#         echo "::set-output name=state_bucket::$state_bucket"

  deploy-test:
    name: 'deploy-test'
    needs: get-deployment-data
    runs-on: ubuntu-latest
    environment: ${{ needs.get-deployment-data.outputs.environment }}
    
    permissions:
      id-token: write
      contents: read

    steps:
    # Checkout the repository to the GitHub Actions runner
    - name: Checkout
      uses: actions/checkout@v2
    
    - name: Configure AWS Credentials
      id: assume_role
      uses: aws-actions/configure-aws-credentials@v1
      with:
        aws-region: ${{ needs.get-deployment-data.outputs.target_region }}
        role-to-assume: ${{ needs.get-deployment-data.outputs.role_arn }}
        role-session-name: TF-Github-Actions
        mask-aws-account-id: 'no'

    - name: Login to Amazon ECR
      id: login-ecr
      uses: aws-actions/amazon-ecr-login@v1

    # - name: proton get-service
    #   id: tf_init
    #   run: |
    #     aws proton --region ap-northeast-1 get-service --name pipeline | jq -r .service.spec > service.yaml
    #     cat service.yaml

    - name: install
      id: install
      run: |
        pip3 install --upgrade --user awscli
        echo 'f6bd1536a743ab170b35c94ed4c7c4479763356bd543af5d391122f4af852460  yq_linux_amd64' > yq_linux_amd64.sha
        wget https://github.com/mikefarah/yq/releases/download/3.4.0/yq_linux_amd64
        sha256sum -c yq_linux_amd64.sha
        sudo mv yq_linux_amd64 /usr/bin/yq
        sudo chmod +x /usr/bin/yq
  
    - name: build
      id: build
      env:
        ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
        IMAGE_REPO_NAME: ${{ github.repository }}
        IMAGE_TAG: ${{ github.sha }}
      run: |
        docker build -t $IMAGE_REPO_NAME:$IMAGE_TAG -f ecs-static-website/Dockerfile .
        docker tag $IMAGE_REPO_NAME:$IMAGE_TAG $ECR_REGISTRY/$IMAGE_REPO_NAME:$IMAGE_TAG
        docker tag $IMAGE_REPO_NAME:$IMAGE_TAG $ECR_REGISTRY/$IMAGE_REPO_NAME:latest
        docker push $ECR_REGISTRY/$IMAGE_REPO_NAME:$IMAGE_TAG
        docker push $ECR_REGISTRY/$IMAGE_REPO_NAME:latest
        echo "image_id=$ECR_REGISTRY/$IMAGE_REPO_NAME:$IMAGE_TAG" >> $GITHUB_ENV
  
    - name: post_build
      id: post_build
      run: |
        aws proton --region ${{ needs.get-deployment-data.outputs.target_region }} get-service --name pipeline | jq -r .service.spec > service.yaml
        # protonからサービスの情報を取得。作業用として、service.yamlに書き出す
        yq w service.yaml 'instances[*].spec.image' \"${{ env.image_id }}\" > rendered_service.yaml
        # service.yamlのうち直前のbuildコマンドで作成したIMAGE_IDを更新
        cat rendered_service.yaml

    - name: proton deploy
      id: proton_deploy
      run: |
        echo "aws proton update-service-instance"
        aws proton --region ${{ needs.get-deployment-data.outputs.target_region }} update-service-instance  \
        --deployment-type CURRENT_VERSION \ #マイナーバージョンまたはメジャーバージョンを更新しない
        # --name $service_instance_name \
        --name tesaki-test-srv-0209 \
        # --service-name $service_name \
        --service-name pipeline \
        --spec "file://rendered_service.yaml"

        echo "aws proton wait service-instance-deployed"
        aws proton --region ${{ needs.get-deployment-data.outputs.target_region }} wait service-instance-deployed \
        --name tesaki-test-srv-0209 --service-name pipeline




  # terraform:
  #   name: 'Terraform'
  #   needs: get-deployment-data
  #   runs-on: ubuntu-latest
  #   environment: ${{ needs.get-deployment-data.outputs.environment }}

  #   permissions:
  #     id-token: write
  #     contents: read
    
  #   defaults:
  #     run:
  #       working-directory: ${{ needs.get-deployment-data.outputs.working_directory }}
  #       shell: bash # Use the Bash shell regardless whether the GitHub Actions runner is ubuntu-latest, macos-latest, or windows-latest

  #   if: needs.get-deployment-data.result == 'success' && needs.get-deployment-data.outputs.is_deleted == 'false'
    
  #   continue-on-error: true

  #   outputs:
  #     success: ${{ steps.mark_success.outputs.success }}

  #   steps:
  #   # Checkout the repository to the GitHub Actions runner
  #   - name: Checkout
  #     uses: actions/checkout@v2
    
  #   - name: Configure AWS Credentials
  #     id: assume_role
  #     uses: aws-actions/configure-aws-credentials@v1
  #     with:
  #       aws-region: ${{ needs.get-deployment-data.outputs.target_region }}
  #       role-to-assume: ${{ needs.get-deployment-data.outputs.role_arn }}
  #       role-session-name: TF-Github-Actions
  #       mask-aws-account-id: 'no'

  #   # Install the latest version of Terraform CLI and configure the Terraform CLI configuration file with a Terraform Cloud user API token
  #   - name: Setup Terraform
  #     id: tf_setup
  #     uses: hashicorp/setup-terraform@v1
  #     with:
  #       terraform_version: 1.0.7
  #       terraform_wrapper: false

  #   # Initialize a new or existing Terraform working directory by creating initial files, loading any remote state, downloading modules, etc.
  #   - name: Terraform Init
  #     id: tf_init
  #     run: terraform init -backend-config="bucket=${{ needs.get-deployment-data.outputs.state_bucket }}" -backend-config="key=${{ needs.get-deployment-data.outputs.working_directory }}terraform.tfstate" -backend-config="region=${{ needs.get-deployment-data.outputs.target_region }}"

  #   # Checks that all Terraform configuration files adhere to a canonical format
  #   - name: Terraform Format
  #     id: tf_fmt
  #     run: terraform fmt -diff -check

  #   # Generates an execution plan for Terraform
  #   - name: Terraform Plan
  #     id: tf_plan
  #     run: terraform plan -var="aws_region=${{ needs.get-deployment-data.outputs.target_region }}"

  #   # On push to main, build or change infrastructure according to Terraform configuration files
  #   # Note: It is recommended to set up a required "strict" status check in your repository for "Terraform Cloud". See the documentation on "strict" required status checks for more information: https://help.github.com/en/github/administering-a-repository/types-of-required-status-checks
  #   - name: Terraform Apply
  #     id: tf_apply
  #     if: github.ref == 'refs/heads/main' && github.event_name == 'push'
  #     run: terraform apply -auto-approve -var="aws_region=${{ needs.get-deployment-data.outputs.target_region }}"
    
  #   # If this completes, then the entire workflow has successfully completed
  #   - name: Mark Success
  #     id: mark_success
  #     run: echo "::set-output name=success::True"

  # notify-proton:
  #   name: 'Notify Proton'
  #   needs: 
  #   - get-deployment-data
  #   - terraform
  #   runs-on: ubuntu-latest
  #   environment: ${{ needs.get-deployment-data.outputs.environment }}

  #   if: github.event_name == 'push' && github.ref == 'refs/heads/main' && needs.get-deployment-data.outputs.is_deleted == 'false'
    
  #   permissions:
  #     id-token: write
  #     contents: read
      
  #   defaults:
  #     run:
  #       working-directory: ${{ needs.get-deployment-data.outputs.working_directory }}
  #       shell: bash # Use the Bash shell regardless whether the GitHub Actions runner is ubuntu-latest, macos-latest, or windows-latest

  #   steps:
  #   # Checkout the repository to the GitHub Actions runner
  #   - name: Checkout
  #     uses: actions/checkout@v2
      
  #   - name: Configure AWS Credentials
  #     id: assume_role
  #     uses: aws-actions/configure-aws-credentials@v1
  #     with:
  #       aws-region: ${{ needs.get-deployment-data.outputs.target_region }}
  #       role-to-assume: ${{ needs.get-deployment-data.outputs.role_arn }}
  #       role-session-name: TF-Github-Actions-Notify-Proton
  #       mask-aws-account-id: 'no'
        
  #   # Initialize a new or existing Terraform working directory by creating initial files, loading any remote state, downloading modules, etc.
  #   - name: Terraform Init
  #     id: tf_init
  #     continue-on-error: true
  #     run: terraform init -backend-config="bucket=${{ needs.get-deployment-data.outputs.state_bucket }}" -backend-config="key=${{ needs.get-deployment-data.outputs.working_directory }}terraform.tfstate" -backend-config="region=${{ needs.get-deployment-data.outputs.target_region }}"

  #   - name: Notify Proton Success
  #     id: notify_success
  #     if: needs.terraform.outputs.success == 'True' && steps.tf_init.outcome == 'success'
  #     run: |
  #       # Get outputs as json
  #       outputs_json=$(terraform output -json)

  #       # Map Terraform output JSON to Proton outputs JSON
  #       formatted_outputs=( $(echo $outputs_json | jq "to_entries|map({key: .key, valueString: .value.value})") )
      
  #       # Notify proton
  #       aws proton notify-resource-deployment-status-change --region ${{ needs.get-deployment-data.outputs.proton_region }} --resource-arn ${{ needs.get-deployment-data.outputs.resource_arn }} --status SUCCEEDED --deployment-id ${{ needs.get-deployment-data.outputs.deployment_id }} --outputs "${formatted_outputs[*]}"
  #       echo "Notify success!"   
        
  #   - name: Notify Proton Failure
  #     if: needs.terraform.outputs.success != 'True' || steps.tf_init.outcome != 'success'
  #     run: |
  #       aws proton notify-resource-deployment-status-change --region ${{ needs.get-deployment-data.outputs.proton_region }} --resource-arn ${{ needs.get-deployment-data.outputs.resource_arn }} --status FAILED --deployment-id ${{ needs.get-deployment-data.outputs.deployment_id }}
  #       echo "Notify failure!"

  # terraform-destroy:
  #   name: 'Run terraform destroy'
  #   needs: 
  #   - get-deployment-data
  #   runs-on: ubuntu-latest
  #   environment: ${{ needs.get-deployment-data.outputs.environment }}

  #   if: github.event_name == 'push' && github.ref == 'refs/heads/main' && needs.get-deployment-data.outputs.is_deleted == 'true'
    
  #   permissions:
  #     id-token: write
  #     contents: read
      
  #   defaults:
  #     run:
  #       working-directory: ${{ needs.get-deployment-data.outputs.working_directory }}
  #       shell: bash # Use the Bash shell regardless whether the GitHub Actions runner is ubuntu-latest, macos-latest, or windows-latest

  #   steps:
  #   # Checkout the repository to the GitHub Actions runner
  #   - name: Checkout
  #     uses: actions/checkout@v2
      
  #   - name: Configure AWS Credentials
  #     id: assume_role
  #     uses: aws-actions/configure-aws-credentials@v1
  #     with:
  #       aws-region: ${{ needs.get-deployment-data.outputs.target_region }}
  #       role-to-assume: ${{ needs.get-deployment-data.outputs.role_arn }}
  #       role-session-name: TF-Github-Actions-Notify-Proton
  #       mask-aws-account-id: 'no'
        
  #   # Initialize a new or existing Terraform working directory by creating initial files, loading any remote state, downloading modules, etc.
  #   - name: Terraform Init
  #     id: tf_init
  #     run: terraform init -backend-config="bucket=${{ needs.get-deployment-data.outputs.state_bucket }}" -backend-config="key=${{ needs.get-deployment-data.outputs.working_directory }}terraform.tfstate" -backend-config="region=${{ needs.get-deployment-data.outputs.target_region }}"
    
  #   - name: Terraform Destroy
  #     id: tf_destroy
  #     run: terraform apply -auto-approve -destroy -var="aws_region=${{ needs.get-deployment-data.outputs.target_region }}"
